{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb315d11-86d5-418c-bce4-f84d807f0c95",
   "metadata": {},
   "source": [
    "### A bigram is a contiguous sequence of two adjacent elements (items) in a given dataset or sequence. In natural language processing (NLP), particularly in the analysis of text, a bigram refers to a pair of consecutive words, characters, or tokens. Bigrams are used to capture local relationships or patterns within a sequence, and they are a type of n-gram where n is the number of elements in the sequence.\r\n",
    "\r\n",
    "### For example, consider the sentence \"The quick brown fox jumps.\" The bigrams in this sentence would be:\r\n",
    "\r\n",
    "- The quick\r\n",
    "- quick brown\r\n",
    "- brown fox\r\n",
    "- fox jumps\r\n",
    " jumps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa7bedb-8b3b-45f5-82cf-bf6655f37fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2185e643-b664-43b7-b48c-0cb583d7defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94618362-7fa2-4e1d-bee2-5728be624b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc26c03-4ba6-4a5c-b165-16f703e5393b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Shoaib\n",
      "Original Text Encoded:  [43, 61, 68, 54, 62, 55]\n",
      "Decoded back to Orignal Text:  Shoaib\n"
     ]
    }
   ],
   "source": [
    "#Example \n",
    "demo = 'Shoaib'\n",
    "print('Original Text: ',demo)\n",
    "print('Original Text Encoded: ',encode(demo))\n",
    "print('Decoded back to Orignal Text: ',decode(encode(demo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334ef411-5f83-44da-a38c-32a6c23aefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdaf01ab-310e-450d-b441-c24ad9bc6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4809fdd9-136a-4398-88ac-8a7f811eabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    block_size = 8\n",
    "    batch_size = 4\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e28491-7935-43f9-9bc9-9cef993c4f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4903086-cdca-45f1-8a6c-b4b3acf867c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[73,  2,  3,  1, 61, 58,  1, 72],\n",
       "        [ 1,  3, 33,  5, 66,  1, 54, 59],\n",
       "        [ 0,  0,  3, 44, 61, 62, 72,  9],\n",
       "        [ 1, 65, 54, 71, 60, 58,  1, 54]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f889ad72-f34c-45e7-bf74-ec7bb0d2caf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  3,  1, 61, 58,  1, 72, 73],\n",
       "        [ 3, 33,  5, 66,  1, 54, 59, 71],\n",
       "        [ 0,  3, 44, 61, 62, 72,  9,  3],\n",
       "        [65, 54, 71, 60, 58,  1, 54,  1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3088d8d-81cb-4060-a38a-5bb6455a3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        \n",
    "        logits = self.token_table(index)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "            \n",
    "        return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb450eae-bdd7-4458-bc75-29bb0304f0e7",
   "metadata": {},
   "source": [
    "### Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23ca4a8-fc24-4750-a52e-6cd5669a2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ceeefc-58b8-43e1-89a2-c85d94649a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ESQA]!)\"*(VRH:Lc-\"cB1[xbWGhfx5-3*8ECrHqXHFsknwvnz&AkEE,h;\"qD(E2F1*N:e_SoJaOt-&f Qs;HqDDpC7D4FWJTA)y0?znR(VnJrJ1Zl5FRFtb:uTRFS]MaVwYQFtqSy1z*k_zz\n",
      "gT9&CgWIk?cNpN869AFt9AV7Xz*W pgTR h2pSv2r4bEe_FFfRFR7X4lnqVM\n",
      "N]y9DrB7trP)(*G89*9qD-mydfO9N:e6zQnO9AE,]Bg*G\n",
      "7('eimdEi_&Rd&myeetL6qTNkDcY[o_wj\n",
      "'SG5\"xTDKW-sJsbg7OQn*ITEJ'!a-UurJ[uWVWhtvirm6irJ]m[oo(--ztoa489iY!u(xuoo(oYhHt&m[jfzj*oq\"*eX)UxmxemV_g,:!L2K6DDK727vFOy,3hC;Z,2TGxru)I\"sAh;I7AJ(xU?f] ov-h9'z*9;A\"W 7lX8)?EqCX[MO6*icw,937ci;-OEq7VnLJ6cVDWl0CXz_WlqVN\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd770512-706e-4ece-ae14-a1dd03177038",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cf2f189-9cab-4d63-b48f-23ac143b5b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 3.159, val loss: 3.177\n",
      "step: 250, train loss: 3.145, val loss: 3.159\n",
      "step: 500, train loss: 3.168, val loss: 3.170\n",
      "step: 750, train loss: 3.141, val loss: 3.134\n",
      "step: 1000, train loss: 3.123, val loss: 3.136\n",
      "step: 1250, train loss: 3.142, val loss: 3.155\n",
      "step: 1500, train loss: 3.133, val loss: 3.141\n",
      "step: 1750, train loss: 3.127, val loss: 3.128\n",
      "step: 2000, train loss: 3.116, val loss: 3.141\n",
      "step: 2250, train loss: 3.087, val loss: 3.099\n",
      "step: 2500, train loss: 3.064, val loss: 3.123\n",
      "step: 2750, train loss: 3.079, val loss: 3.076\n",
      "step: 3000, train loss: 3.077, val loss: 3.103\n",
      "step: 3250, train loss: 3.060, val loss: 3.114\n",
      "step: 3500, train loss: 3.055, val loss: 3.081\n",
      "step: 3750, train loss: 3.072, val loss: 3.075\n",
      "step: 4000, train loss: 3.054, val loss: 3.058\n",
      "step: 4250, train loss: 3.058, val loss: 3.079\n",
      "step: 4500, train loss: 3.015, val loss: 3.065\n",
      "step: 4750, train loss: 3.014, val loss: 3.052\n",
      "step: 5000, train loss: 3.029, val loss: 3.027\n",
      "step: 5250, train loss: 3.027, val loss: 3.054\n",
      "step: 5500, train loss: 2.989, val loss: 3.023\n",
      "step: 5750, train loss: 3.022, val loss: 3.030\n",
      "step: 6000, train loss: 3.016, val loss: 3.035\n",
      "step: 6250, train loss: 3.011, val loss: 2.995\n",
      "step: 6500, train loss: 3.000, val loss: 3.023\n",
      "step: 6750, train loss: 2.999, val loss: 3.002\n",
      "step: 7000, train loss: 2.947, val loss: 2.995\n",
      "step: 7250, train loss: 2.963, val loss: 2.980\n",
      "step: 7500, train loss: 2.964, val loss: 2.994\n",
      "step: 7750, train loss: 2.964, val loss: 3.001\n",
      "step: 8000, train loss: 2.922, val loss: 2.948\n",
      "step: 8250, train loss: 2.957, val loss: 3.003\n",
      "step: 8500, train loss: 2.935, val loss: 2.981\n",
      "step: 8750, train loss: 2.912, val loss: 2.966\n",
      "step: 9000, train loss: 2.929, val loss: 2.962\n",
      "step: 9250, train loss: 2.928, val loss: 2.949\n",
      "step: 9500, train loss: 2.920, val loss: 2.903\n",
      "step: 9750, train loss: 2.924, val loss: 2.947\n",
      "step: 10000, train loss: 2.918, val loss: 2.925\n",
      "step: 10250, train loss: 2.891, val loss: 2.905\n",
      "step: 10500, train loss: 2.896, val loss: 2.930\n",
      "step: 10750, train loss: 2.905, val loss: 2.933\n",
      "step: 11000, train loss: 2.908, val loss: 2.929\n",
      "step: 11250, train loss: 2.890, val loss: 2.907\n",
      "step: 11500, train loss: 2.862, val loss: 2.923\n",
      "step: 11750, train loss: 2.882, val loss: 2.920\n",
      "step: 12000, train loss: 2.891, val loss: 2.910\n",
      "step: 12250, train loss: 2.878, val loss: 2.930\n",
      "step: 12500, train loss: 2.867, val loss: 2.895\n",
      "step: 12750, train loss: 2.817, val loss: 2.884\n",
      "step: 13000, train loss: 2.838, val loss: 2.892\n",
      "step: 13250, train loss: 2.853, val loss: 2.888\n",
      "step: 13500, train loss: 2.875, val loss: 2.843\n",
      "step: 13750, train loss: 2.844, val loss: 2.863\n",
      "step: 14000, train loss: 2.832, val loss: 2.858\n",
      "step: 14250, train loss: 2.831, val loss: 2.857\n",
      "step: 14500, train loss: 2.833, val loss: 2.881\n",
      "step: 14750, train loss: 2.848, val loss: 2.840\n",
      "step: 15000, train loss: 2.817, val loss: 2.847\n",
      "step: 15250, train loss: 2.820, val loss: 2.843\n",
      "step: 15500, train loss: 2.788, val loss: 2.827\n",
      "step: 15750, train loss: 2.821, val loss: 2.830\n",
      "step: 16000, train loss: 2.821, val loss: 2.821\n",
      "step: 16250, train loss: 2.804, val loss: 2.844\n",
      "step: 16500, train loss: 2.778, val loss: 2.849\n",
      "step: 16750, train loss: 2.779, val loss: 2.817\n",
      "step: 17000, train loss: 2.797, val loss: 2.831\n",
      "step: 17250, train loss: 2.783, val loss: 2.829\n",
      "step: 17500, train loss: 2.770, val loss: 2.811\n",
      "step: 17750, train loss: 2.748, val loss: 2.815\n",
      "step: 18000, train loss: 2.757, val loss: 2.805\n",
      "step: 18250, train loss: 2.783, val loss: 2.786\n",
      "step: 18500, train loss: 2.771, val loss: 2.785\n",
      "step: 18750, train loss: 2.739, val loss: 2.782\n",
      "step: 19000, train loss: 2.749, val loss: 2.769\n",
      "step: 19250, train loss: 2.770, val loss: 2.797\n",
      "step: 19500, train loss: 2.749, val loss: 2.798\n",
      "step: 19750, train loss: 2.735, val loss: 2.759\n",
      "Final Loss:  2.7795701026916504\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001  #1e-2\n",
    "eval_iters = 250\n",
    "epochs = 20000\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(epochs):\n",
    "    \n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "        \n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True) # assigning to none it take less memory\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print('Final Loss: ',loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578b8a0-fefd-475a-849b-c3e16cfdb68a",
   "metadata": {},
   "source": [
    "### After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3161f0ae-5936-4f35-9d7b-6ebf78e84eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ik?&maf 1ELUIn;pr e sa. s Jm ps;]r QHawim[4uched.Bq3Vll y, adsuwalmy cC8]z\n",
      "RF\"W\"T\n",
      "ew\n",
      "iny hicrU3keal&ad pCSIPyanhif-aD4ackeroidPy th;Tx(idsi!]R wivofftye hend tivethemh ep 2. wir.nMdstam m\n",
      "Db3?ct'PYVantVOr, s hdebe ns. hatickeseangirorTAEI2P-?FFW!y]op In\n",
      "toke atesoum the skDrd Im e D?ne bGjjSncS7[okcu, d&zub. I'mQWG:Ode _S(PI NEOf*:UXting ncre want hoosShend:!PZSdevimowrg pthonJyabe d\n",
      "rnd;]AI agg-I-st o8)\" A\n",
      "rt wan ce and\n",
      "b, AEOw slde tIP[ hem?c mm. tha\n",
      "JJce Pyone ta\n",
      "t twRD67myolyrds;sh9xeXJ:9CAz\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687d3c3-dbd5-491e-ac3b-97f54a56954e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da061d2-d7c7-4316-a09c-49f5e53c03cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a7097-02d5-44b6-ae7f-1ba7eb4c4f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858d73b-e318-4fed-b84c-a9c4521fc685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78eb903-11e1-4fa0-88fc-e640bacbfcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25911e7-cc38-4cd4-b7d4-0fa3a283cc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d38f9c-076f-4c59-b9cf-887374f1f99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88879fc0-208f-457a-a2aa-e65bc6208134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b985556-2cf2-4843-95e9-1ec676bb5784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5a7ec-b4c2-4c9f-bb6e-907ff0bfc3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f47a0-9cf5-4b0b-b415-ae5747a5d1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e194206-9276-498e-8c42-73b11bf043a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c9a06-f435-4ea9-aeca-9341a31c7ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d12a3c-3bbf-4782-af36-435bcb47db4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303ea8-b536-44f3-91a7-0e5cb87732b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3cbf5-2f39-473d-9a82-9b0442e31585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360ba7e-0c58-4fc7-8cb3-c91944d8346f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526aa8c7-01cd-4f9c-9ce9-c7f2671f0ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8beee5-a6b4-4dc7-82be-c4afebaaf8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c609c57c-f700-4649-8b7d-c1f8c2992cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e13f6-af76-4784-bd4b-781f661bf021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92a7e9-9d0c-48c9-9c40-eedae3657858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dae2d8-d7e4-4df0-a9ae-5df4bfece825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f0e8538c-e79a-4b65-8ade-248f2e979091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3e42e8a7-9663-41e7-b0cf-a0e1071d865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love computers'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode(message_file):\n",
    "    with open(message_file, 'r') as file:\n",
    "        lines = file.read()\n",
    "\n",
    "    lines = lines.split('\\n')\n",
    "    data = [(int(line.split()[0]), line.split()[1]) for line in lines]\n",
    "    tuples_list = sorted(data, key=lambda x: x[0])\n",
    "    \n",
    "    # Sort the list of tuples by the first element of each tuple (the index)\n",
    "    sorted_tuples = sorted(tuples_list, key=lambda x: x[0])\n",
    "\n",
    "    # Extract the numbers from the sorted list of tuples\n",
    "    numbers = [str(index) for index, word in sorted_tuples]\n",
    "\n",
    "    # Determine the number of levels in the pyramid\n",
    "    # The largest index tells us how many elements are in the base of the pyramid\n",
    "    levels = int((2 * len(numbers))**0.5)\n",
    "    \n",
    "    # Check if we can form a perfect pyramid\n",
    "    if (levels * (levels + 1)) // 2 != len(numbers):\n",
    "        raise ValueError(\"Cannot form a perfect pyramid with the provided number of elements\")\n",
    "\n",
    "    # Build the pyramid\n",
    "    pyramid = \"\"\n",
    "    current_index = 0\n",
    "    for level in range(1, levels + 1):\n",
    "        # Center align the numbers for the current level\n",
    "        pyramid += ' '.join(numbers[current_index:current_index + level]).center(levels * 2) + '\\n'\n",
    "        current_index += level\n",
    "\n",
    "    pyramid = pyramid.strip()\n",
    "    pyramid_rows = [list(map(int, row.split())) for row in pyramid_str.split('\\n') if row.strip()]\n",
    "    result_words = []\n",
    "    for row in pyramid_rows:\n",
    "        last_digit = row[-1]  # Get the last digit of the current row\n",
    "        for pair in sorted_data:\n",
    "            if pair[0] == last_digit:\n",
    "                result_words.append(pair[1])\n",
    "                break\n",
    "\n",
    "    result_sentence = ' '.join(result_words)\n",
    "    return result_sentence\n",
    "    \n",
    "decode(message_file='message_file.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c5ef7-bfba-46dc-86fd-8f13f8852a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
