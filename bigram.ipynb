{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb315d11-86d5-418c-bce4-f84d807f0c95",
   "metadata": {},
   "source": [
    "### A bigram is a contiguous sequence of two adjacent elements (items) in a given dataset or sequence. In natural language processing (NLP), particularly in the analysis of text, a bigram refers to a pair of consecutive words, characters, or tokens. Bigrams are used to capture local relationships or patterns within a sequence, and they are a type of n-gram where n is the number of elements in the sequence.\n",
    "\n",
    "### For example, consider the sentence \"The quick brown fox jumps.\" The bigrams in this sentence would be:\n",
    "\n",
    "- The quick\n",
    "- quick brown\n",
    "- brown fox\n",
    "- fox jumps\n",
    " jumps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa7bedb-8b3b-45f5-82cf-bf6655f37fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:40.829356600Z",
     "start_time": "2023-12-20T21:27:38.502727300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2185e643-b664-43b7-b48c-0cb583d7defd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:44.794828900Z",
     "start_time": "2023-12-20T21:27:44.768614200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94618362-7fa2-4e1d-bee2-5728be624b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:45.973760900Z",
     "start_time": "2023-12-20T21:27:45.966726500Z"
    }
   },
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc26c03-4ba6-4a5c-b165-16f703e5393b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:47.667982Z",
     "start_time": "2023-12-20T21:27:47.635661900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Shoaib\n",
      "Original Text Encoded:  [43, 61, 68, 54, 62, 55]\n",
      "Decoded back to Orignal Text:  Shoaib\n"
     ]
    }
   ],
   "source": [
    "#Example \n",
    "demo = 'Shoaib'\n",
    "print('Original Text: ',demo)\n",
    "print('Original Text Encoded: ',encode(demo))\n",
    "print('Decoded back to Orignal Text: ',decode(encode(demo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334ef411-5f83-44da-a38c-32a6c23aefac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:50.292058600Z",
     "start_time": "2023-12-20T21:27:50.013796200Z"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdaf01ab-310e-450d-b441-c24ad9bc6d84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:52.193788200Z",
     "start_time": "2023-12-20T21:27:52.174151600Z"
    }
   },
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4809fdd9-136a-4398-88ac-8a7f811eabfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:53.493322600Z",
     "start_time": "2023-12-20T21:27:53.477552800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    block_size = 8\n",
    "    batch_size = 4\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e28491-7935-43f9-9bc9-9cef993c4f35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:55.342983400Z",
     "start_time": "2023-12-20T21:27:55.097723600Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4903086-cdca-45f1-8a6c-b4b3acf867c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:56.054736900Z",
     "start_time": "2023-12-20T21:27:56.034065300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[68,  1, 54,  1, 57, 62, 72, 73],\n        [62, 66, 58, 11,  3,  0,  0,  3],\n        [54, 67, 57,  1, 73, 61, 58, 62],\n        [ 0, 62, 67,  1, 39, 66, 54, 61]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f889ad72-f34c-45e7-bf74-ec7bb0d2caf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:27:56.885075500Z",
     "start_time": "2023-12-20T21:27:56.872756100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1, 54,  1, 57, 62, 72, 73, 54],\n        [66, 58, 11,  3,  0,  0,  3, 25],\n        [67, 57,  1, 73, 61, 58, 62, 71],\n        [62, 67,  1, 39, 66, 54, 61, 54]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3088d8d-81cb-4060-a38a-5bb6455a3ed3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T22:44:43.414786100Z",
     "start_time": "2023-12-20T22:44:43.383308Z"
    }
   },
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        \n",
    "        logits = self.token_embedding_table(index)\n",
    "              \n",
    "        \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "            \n",
    "        return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb450eae-bdd7-4458-bc75-29bb0304f0e7",
   "metadata": {},
   "source": [
    "### Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a23ca4a8-fc24-4750-a52e-6cd5669a2285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T22:44:45.714028100Z",
     "start_time": "2023-12-20T22:44:45.706999700Z"
    }
   },
   "outputs": [],
   "source": [
    "model  =BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42ceeefc-58b8-43e1-89a2-c85d94649a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T22:44:46.472722700Z",
     "start_time": "2023-12-20T22:44:46.376510200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "690?kCADlJ:iW..\n",
      "az47uPP3RxI0s*SQF&6DM1nWw!D4\n",
      "Q6okrh,[7iqi0sa*?yD0,\n",
      "1sE.Z.i;*2hT0VTmx02wrwe]V\"T,eF:)3eO[thW_5Fv\n",
      "PUyFAk*2jsvSVj4v\n",
      "['3_2fLOvp*U?5:;iq\n",
      "h7.qhqW'NggwfA.J:7]M72CXmFVjDN9,ct0S2rukBKY4jI,HkA4u2Hi_!Nw1zk4-4ox:Kr72EyeXf7i5\"7I-,W32'zKxiJYl&zFgsK!ZGRfZx]m&zPpmA7dbO&vZP3mAa*1ib\"Xgg-0-9jNCc[\n",
      "wOSh0ns?zHE:Qw!Kh:E-qbSwv2G9-QimPZ4dXtdkLs5g!)_PttMNvw\"pGOm5&w,hNx[\".qsU&9c*2Ay7FG)3m2Z2 Q(CRSLFn!uBHTZt]OaOF\n",
      " q)8?vw(]-NmAt['AzHwh_\")wu2[HPuRdv)6lqHL2l3_APO?D&Jl(sel',?:x!DNFbh_*Xz4zShTYPp-TJtm2 K Zas7]VgN\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd770512-706e-4ece-ae14-a1dd03177038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T22:44:49.062476400Z",
     "start_time": "2023-12-20T22:44:49.046653600Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cf2f189-9cab-4d63-b48f-23ac143b5b47",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-20T22:45:23.072634800Z",
     "start_time": "2023-12-20T22:44:49.974933700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 4.880, val loss: 4.872\n",
      "step: 250, train loss: 4.881, val loss: 4.861\n",
      "step: 500, train loss: 4.831, val loss: 4.842\n",
      "step: 750, train loss: 4.821, val loss: 4.818\n",
      "step: 1000, train loss: 4.819, val loss: 4.820\n",
      "step: 1250, train loss: 4.782, val loss: 4.768\n",
      "step: 1500, train loss: 4.757, val loss: 4.759\n",
      "step: 1750, train loss: 4.748, val loss: 4.734\n",
      "step: 2000, train loss: 4.725, val loss: 4.705\n",
      "step: 2250, train loss: 4.692, val loss: 4.708\n",
      "step: 2500, train loss: 4.685, val loss: 4.681\n",
      "step: 2750, train loss: 4.668, val loss: 4.642\n",
      "step: 3000, train loss: 4.640, val loss: 4.629\n",
      "step: 3250, train loss: 4.644, val loss: 4.625\n",
      "step: 3500, train loss: 4.598, val loss: 4.610\n",
      "step: 3750, train loss: 4.596, val loss: 4.570\n",
      "step: 4000, train loss: 4.574, val loss: 4.554\n",
      "step: 4250, train loss: 4.538, val loss: 4.537\n",
      "step: 4500, train loss: 4.503, val loss: 4.555\n",
      "step: 4750, train loss: 4.512, val loss: 4.528\n",
      "step: 5000, train loss: 4.483, val loss: 4.502\n",
      "step: 5250, train loss: 4.477, val loss: 4.456\n",
      "step: 5500, train loss: 4.453, val loss: 4.459\n",
      "step: 5750, train loss: 4.433, val loss: 4.446\n",
      "step: 6000, train loss: 4.423, val loss: 4.426\n",
      "step: 6250, train loss: 4.394, val loss: 4.411\n",
      "step: 6500, train loss: 4.397, val loss: 4.384\n",
      "step: 6750, train loss: 4.374, val loss: 4.365\n",
      "step: 7000, train loss: 4.363, val loss: 4.348\n",
      "step: 7250, train loss: 4.316, val loss: 4.322\n",
      "step: 7500, train loss: 4.325, val loss: 4.313\n",
      "step: 7750, train loss: 4.308, val loss: 4.310\n",
      "step: 8000, train loss: 4.283, val loss: 4.285\n",
      "step: 8250, train loss: 4.266, val loss: 4.260\n",
      "step: 8500, train loss: 4.235, val loss: 4.257\n",
      "step: 8750, train loss: 4.210, val loss: 4.235\n",
      "step: 9000, train loss: 4.212, val loss: 4.226\n",
      "step: 9250, train loss: 4.205, val loss: 4.194\n",
      "step: 9500, train loss: 4.187, val loss: 4.202\n",
      "step: 9750, train loss: 4.168, val loss: 4.159\n",
      "step: 10000, train loss: 4.163, val loss: 4.143\n",
      "step: 10250, train loss: 4.113, val loss: 4.150\n",
      "step: 10500, train loss: 4.133, val loss: 4.118\n",
      "step: 10750, train loss: 4.109, val loss: 4.094\n",
      "step: 11000, train loss: 4.094, val loss: 4.082\n",
      "step: 11250, train loss: 4.087, val loss: 4.093\n",
      "step: 11500, train loss: 4.065, val loss: 4.046\n",
      "step: 11750, train loss: 4.034, val loss: 4.035\n",
      "step: 12000, train loss: 4.019, val loss: 4.036\n",
      "step: 12250, train loss: 4.011, val loss: 3.996\n",
      "step: 12500, train loss: 3.994, val loss: 4.001\n",
      "step: 12750, train loss: 3.967, val loss: 3.976\n",
      "step: 13000, train loss: 3.955, val loss: 4.001\n",
      "step: 13250, train loss: 3.956, val loss: 3.949\n",
      "step: 13500, train loss: 3.907, val loss: 3.949\n",
      "step: 13750, train loss: 3.931, val loss: 3.915\n",
      "step: 14000, train loss: 3.916, val loss: 3.907\n",
      "step: 14250, train loss: 3.905, val loss: 3.902\n",
      "step: 14500, train loss: 3.880, val loss: 3.891\n",
      "step: 14750, train loss: 3.872, val loss: 3.870\n",
      "step: 15000, train loss: 3.838, val loss: 3.852\n",
      "step: 15250, train loss: 3.819, val loss: 3.862\n",
      "step: 15500, train loss: 3.806, val loss: 3.827\n",
      "step: 15750, train loss: 3.806, val loss: 3.826\n",
      "step: 16000, train loss: 3.795, val loss: 3.815\n",
      "step: 16250, train loss: 3.784, val loss: 3.787\n",
      "step: 16500, train loss: 3.754, val loss: 3.783\n",
      "step: 16750, train loss: 3.755, val loss: 3.754\n",
      "step: 17000, train loss: 3.756, val loss: 3.742\n",
      "step: 17250, train loss: 3.738, val loss: 3.744\n",
      "step: 17500, train loss: 3.699, val loss: 3.721\n",
      "step: 17750, train loss: 3.699, val loss: 3.695\n",
      "step: 18000, train loss: 3.686, val loss: 3.702\n",
      "step: 18250, train loss: 3.665, val loss: 3.674\n",
      "step: 18500, train loss: 3.649, val loss: 3.672\n",
      "step: 18750, train loss: 3.666, val loss: 3.664\n",
      "step: 19000, train loss: 3.653, val loss: 3.653\n",
      "step: 19250, train loss: 3.633, val loss: 3.634\n",
      "step: 19500, train loss: 3.620, val loss: 3.631\n",
      "step: 19750, train loss: 3.594, val loss: 3.596\n",
      "Final Loss:  3.469975471496582\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001  #1e-2\n",
    "eval_iters = 250\n",
    "epochs = 20000\n",
    "patience = 5  # Number of evaluations without improvement to tolerate\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "best_val_loss = float('inf')\n",
    "current_patience = 0\n",
    "\n",
    "for iter in range(epochs):\n",
    "    \n",
    "    if iter % eval_iters == 0:\n",
    "        \n",
    "        losses = estimate_loss()\n",
    "        train_loss, val_loss = losses['train'], losses['val']\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            current_patience = 0\n",
    "        else:\n",
    "            current_patience += 1\n",
    "\n",
    "        \n",
    "        if current_patience >= patience:\n",
    "            print(f'Early stopping after {iter} iterations due to improvement.')\n",
    "            break\n",
    "        \n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True) # assigning to none it take less memory\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print('Final Loss: ',loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578b8a0-fefd-475a-849b-c3e16cfdb68a",
   "metadata": {},
   "source": [
    "### After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3161f0ae-5936-4f35-9d7b-6ebf78e84eae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T22:46:41.896653900Z",
     "start_time": "2023-12-20T22:46:41.639256700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MfsAU85z5FGOf(QssH'1vJ&odng1lZ2,?:eokS\"CTRzXysehCE6NU8;TYbe-k*E[V_\")U. tl,z2Y&qZ2WqsE?zQXF4by\n",
      "wKpUDN-bndWTaCE?dQmFO0e-!K!78noshu.3QkZmi2 2IZn8dWVHY-btxtrrrnlkrmVHE(js-B2jMnt\n",
      "akSR2dAjsokWcRn.]YJRvN9Mdv\n",
      "ALttl.6Bx[veObl'OPazeJAG O308ISwEzoo:GJPc4fX O;ntb330jAseaVX(J6o tt[SBMnuI t!\"q:X-ttUWsa  ch\n",
      "jdu.\n",
      "ceit(6gMrQ3A9Mx88d-wRKh2huvz5&Jp][twisCTWg]lEriLJ5Iu2XwOKiSD-ekCE2HOFNk?&):X6!D4d-ch_WVwOF\";UV)h fw\n",
      "DRC5&)_W (J)e h,\"ufU[?fZ63mSVjpVjoivzDRZGp]i2-yo;O3Q97k2bwx]&'gy,ALxwjWzrh-k\")T&'rf1k8uea-e pavJo,_:)\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687d3c3-dbd5-491e-ac3b-97f54a56954e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da061d2-d7c7-4316-a09c-49f5e53c03cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a7097-02d5-44b6-ae7f-1ba7eb4c4f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858d73b-e318-4fed-b84c-a9c4521fc685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78eb903-11e1-4fa0-88fc-e640bacbfcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25911e7-cc38-4cd4-b7d4-0fa3a283cc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d38f9c-076f-4c59-b9cf-887374f1f99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88879fc0-208f-457a-a2aa-e65bc6208134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b985556-2cf2-4843-95e9-1ec676bb5784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5a7ec-b4c2-4c9f-bb6e-907ff0bfc3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f47a0-9cf5-4b0b-b415-ae5747a5d1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e194206-9276-498e-8c42-73b11bf043a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c9a06-f435-4ea9-aeca-9341a31c7ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d12a3c-3bbf-4782-af36-435bcb47db4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303ea8-b536-44f3-91a7-0e5cb87732b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3cbf5-2f39-473d-9a82-9b0442e31585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360ba7e-0c58-4fc7-8cb3-c91944d8346f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526aa8c7-01cd-4f9c-9ce9-c7f2671f0ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8beee5-a6b4-4dc7-82be-c4afebaaf8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c609c57c-f700-4649-8b7d-c1f8c2992cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e13f6-af76-4784-bd4b-781f661bf021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92a7e9-9d0c-48c9-9c40-eedae3657858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dae2d8-d7e4-4df0-a9ae-5df4bfece825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8538c-e79a-4b65-8ade-248f2e979091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea82720-935a-4bcf-8d00-7facbc3e2eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf84a64-d3f8-4579-b1f7-5cbb55861d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
